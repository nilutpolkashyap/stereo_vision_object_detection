{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3694: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCameraRO'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-672faec7a089>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m############## CALIBRATION #######################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mretL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcameraMatrixL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecsL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecsL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpointsL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframeSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[0mheightL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidthL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannelsL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mnewCameraMatrixL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_L\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOptimalNewCameraMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcameraMatrixL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidthL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheightL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidthL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheightL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3694: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCameraRO'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "\n",
    "\n",
    "################ FIND CHESSBOARD CORNERS - OBJECT POINTS AND IMAGE POINTS #############################\n",
    "\n",
    "chessboardSize = (7,7)\n",
    "frameSize = (640,640)\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "size_of_chessboard_squares_mm = 20\n",
    "objp = objp * size_of_chessboard_squares_mm\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d points in image plane.\n",
    "imgpointsR = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "imagesLeft = sorted(glob.glob('images/stereoLeft/*.png'))\n",
    "imagesRight = sorted(glob.glob('images/stereoRight/*.png'))\n",
    "\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv.imshow('img left', imgL)\n",
    "        cv.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv.imshow('img right', imgR)\n",
    "        cv.waitKey(1000)\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############## CALIBRATION #######################################################\n",
    "\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))\n",
    "\n",
    "\n",
    "\n",
    "########## Stereo Vision Calibration #############################################\n",
    "\n",
    "flags = 0\n",
    "flags |= cv.CALIB_FIX_INTRINSIC\n",
    "# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# Hence intrinsic parameters are the same \n",
    "\n",
    "criteria_stereo= (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## Stereo Rectification #################################################\n",
    "\n",
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "stereoMapR = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv.FileStorage('stereoMap.xml', cv.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "\n",
    "\n",
    "################ FIND CHESSBOARD CORNERS - OBJECT POINTS AND IMAGE POINTS #############################\n",
    "\n",
    "chessboardSize = (7,3)\n",
    "frameSize = (640,640)\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "size_of_chessboard_squares_mm = 20\n",
    "objp = objp * size_of_chessboard_squares_mm\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d points in image plane.\n",
    "imgpointsR = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "imagesLeft = sorted(glob.glob('images/stereoLeft/*.png'))\n",
    "imagesRight = sorted(glob.glob('images/stereoRight/*.png'))\n",
    "\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv.imshow('img left', imgL)\n",
    "        cv.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv.imshow('img right', imgR)\n",
    "        cv.waitKey(10000)\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesLeft = sorted(glob.glob('images/stereoLeft/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/stereoLeft\\\\imageL0.png',\n",
       " 'images/stereoLeft\\\\imageL1.png',\n",
       " 'images/stereoLeft\\\\imageL2.png',\n",
       " 'images/stereoLeft\\\\imageL3.png',\n",
       " 'images/stereoLeft\\\\imageL4.png',\n",
       " 'images/stereoLeft\\\\imageL5.png',\n",
       " 'images/stereoLeft\\\\imageL6.png',\n",
       " 'images/stereoLeft\\\\imageL7.png',\n",
       " 'images/stereoLeft\\\\imageL8.png']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesRight = sorted(glob.glob('images/stereoRight/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/stereoRight\\\\imageR0.png',\n",
       " 'images/stereoRight\\\\imageR1.png',\n",
       " 'images/stereoRight\\\\imageR2.png',\n",
       " 'images/stereoRight\\\\imageR3.png',\n",
       " 'images/stereoRight\\\\imageR4.png',\n",
       " 'images/stereoRight\\\\imageR5.png',\n",
       " 'images/stereoRight\\\\imageR6.png',\n",
       " 'images/stereoRight\\\\imageR7.png',\n",
       " 'images/stereoRight\\\\imageR8.png']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images/stereoRight\\imageR0.png\n",
      "1 images/stereoRight\\imageR1.png\n",
      "2 images/stereoRight\\imageR2.png\n",
      "3 images/stereoRight\\imageR3.png\n",
      "4 images/stereoRight\\imageR4.png\n",
      "5 images/stereoRight\\imageR5.png\n",
      "6 images/stereoRight\\imageR6.png\n",
      "7 images/stereoRight\\imageR7.png\n",
      "8 images/stereoRight\\imageR8.png\n"
     ]
    }
   ],
   "source": [
    "numb = len(imagesRight)\n",
    "for i in range(numb):\n",
    "    print(i,imagesRight[i])\n",
    "#     print(\"\\n\")\n",
    "    numb += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "chessboardSize = (7,3)\n",
    "frameSize = (640,320)\n",
    "num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "images/stereoRight\\imageR0.png\n",
      "True True\n",
      "1\n",
      "images/stereoRight\\imageR1.png\n",
      "True True\n",
      "2\n",
      "images/stereoRight\\imageR2.png\n",
      "True True\n",
      "3\n",
      "images/stereoRight\\imageR3.png\n",
      "True True\n",
      "4\n",
      "images/stereoRight\\imageR4.png\n",
      "True True\n",
      "5\n",
      "images/stereoRight\\imageR5.png\n",
      "True True\n",
      "6\n",
      "images/stereoRight\\imageR6.png\n",
      "True True\n",
      "7\n",
      "images/stereoRight\\imageR7.png\n",
      "True True\n",
      "8\n",
      "images/stereoRight\\imageR8.png\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "    \n",
    "    if retL and retR == True:\n",
    "        print(num)\n",
    "        print(imagesRight[num])\n",
    "        print(retL, retR)\n",
    "#         print(cornersL)\n",
    "#         print(cornersR)\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "\n",
    "\n",
    "################ FIND CHESSBOARD CORNERS - OBJECT POINTS AND IMAGE POINTS #############################\n",
    "\n",
    "chessboardSize = (7,3)\n",
    "frameSize = (640,320)\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "size_of_chessboard_squares_mm = 45\n",
    "objp = objp * size_of_chessboard_squares_mm\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d points in image plane.\n",
    "imgpointsR = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "imagesLeft = sorted(glob.glob('images/stereoLeft/*.png'))\n",
    "imagesRight = sorted(glob.glob('images/stereoRight/*.png'))\n",
    "\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv.imshow('img left', imgL)\n",
    "        cv.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv.imshow('img right', imgR)\n",
    "        cv.waitKey(1000)\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = 0\n",
    "flags |= cv.CALIB_FIX_INTRINSIC\n",
    "# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# Hence intrinsic parameters are the same \n",
    "\n",
    "criteria_stereo= (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "stereoMapR = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv.FileStorage('stereoMap.xml', cv.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Camera parameters to undistort and rectify images\n",
    "cv_file = cv2.FileStorage()\n",
    "cv_file.open('stereoMap.xml', cv2.FileStorage_READ)\n",
    "\n",
    "stereoMapL_x = cv_file.getNode('stereoMapL_x').mat()\n",
    "stereoMapL_y = cv_file.getNode('stereoMapL_y').mat()\n",
    "stereoMapR_x = cv_file.getNode('stereoMapR_x').mat()\n",
    "stereoMapR_y = cv_file.getNode('stereoMapR_y').mat()\n",
    "\n",
    "\n",
    "# Open both cameras\n",
    "cap_right = cv2.VideoCapture(2, cv2.CAP_DSHOW)                    \n",
    "cap_left =  cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "\n",
    "while(cap_right.isOpened() and cap_left.isOpened()):\n",
    "\n",
    "    succes_right, frame_right = cap_right.read()\n",
    "    succes_left, frame_left = cap_left.read()\n",
    "\n",
    "    # Undistort and rectify images\n",
    "    frame_right = cv2.remap(frame_right, stereoMapR_x, stereoMapR_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    frame_left = cv2.remap(frame_left, stereoMapL_x, stereoMapL_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "                     \n",
    "    # Show the frames\n",
    "    cv2.imshow(\"frame right\", frame_right) \n",
    "    cv2.imshow(\"frame left\", frame_left)\n",
    "\n",
    "\n",
    "    # Hit \"q\" to close the window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# Release and destroy all windows before termination\n",
    "cap_right.release()\n",
    "cap_left.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(queue):\n",
    "    # Get frame from queue\n",
    "    frame = queue.get()\n",
    "    # Convert frame to OpenCV format and return\n",
    "    return frame.getCvFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonoCamera(pipeline, isLeft):\n",
    "    # Configure mono camera\n",
    "    mono = pipeline.createMonoCamera()\n",
    "\n",
    "    # Set Camera Resolution\n",
    "    mono.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "    \n",
    "    if isLeft:\n",
    "        # Get left camera\n",
    "        mono.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "    else :\n",
    "        # Get right camera\n",
    "        mono.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    return mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import depthai as dai\n",
    "\n",
    "# Camera parameters to undistort and rectify images\n",
    "cv_file = cv2.FileStorage()\n",
    "cv_file.open('stereoMap.xml', cv2.FileStorage_READ)\n",
    "\n",
    "stereoMapL_x = cv_file.getNode('stereoMapL_x').mat()\n",
    "stereoMapL_y = cv_file.getNode('stereoMapL_y').mat()\n",
    "stereoMapR_x = cv_file.getNode('stereoMapR_x').mat()\n",
    "stereoMapR_y = cv_file.getNode('stereoMapR_y').mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    pipeline = dai.Pipeline()\n",
    "    \n",
    "    # Set up left and right cameras\n",
    "    monoLeft = getMonoCamera(pipeline, isLeft = True)\n",
    "    monoRight = getMonoCamera(pipeline, isLeft = False)\n",
    "    \n",
    "    # Set output Xlink for left camera\n",
    "    xoutLeft = pipeline.createXLinkOut()\n",
    "    xoutLeft.setStreamName(\"left\")\n",
    "    \n",
    "    # Set output Xlink for right camera\n",
    "    xoutRight = pipeline.createXLinkOut()\n",
    "    xoutRight.setStreamName(\"right\")\n",
    "    \n",
    "    # Attach cameras to output Xlink\n",
    "    monoLeft.out.link(xoutLeft.input)\n",
    "    monoRight.out.link(xoutRight.input)\n",
    "    \n",
    "    # Pipeline is defined, now we can connect to the device\n",
    "    with dai.Device(pipeline) as device:\n",
    "        \n",
    "        # Get output queues. \n",
    "        leftQueue = device.getOutputQueue(name=\"left\", maxSize=1)\n",
    "        rightQueue = device.getOutputQueue(name=\"right\", maxSize=1)\n",
    "        \n",
    "        while(True):\n",
    "            # Get left frame\n",
    "            leftFrame = getFrame(leftQueue)\n",
    "            # Get right frame\n",
    "            rightFrame = getFrame(rightQueue)\n",
    "            \n",
    "            frame_right = cv2.remap(rightFrame, stereoMapR_x, stereoMapR_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "            frame_left = cv2.remap(leftFrame, stereoMapL_x, stereoMapL_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "            \n",
    "            cv2.imshow(\"Left Frame\", leftFrame)\n",
    "            cv2.imshow(\"Right Frame\", rightFrame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "                \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def find_depth(right_point, left_point, frame_right, frame_left, baseline,f, alpha):\n",
    "\n",
    "    # CONVERT FOCAL LENGTH f FROM [mm] TO [pixel]:\n",
    "    height_right, width_right, depth_right = frame_right.shape\n",
    "    height_left, width_left, depth_left = frame_left.shape\n",
    "\n",
    "    if width_right == width_left:\n",
    "        f_pixel = (width_right * 0.5) / np.tan(alpha * 0.5 * np.pi/180)\n",
    "\n",
    "    else:\n",
    "        print('Left and right camera frames do not have the same pixel width')\n",
    "\n",
    "    x_right = right_point[0]\n",
    "    x_left = left_point[0]\n",
    "\n",
    "    # CALCULATE THE DISPARITY:\n",
    "    disparity = x_left-x_right      #Displacement between left and right frames [pixels]\n",
    "\n",
    "    # CALCULATE DEPTH z:\n",
    "    zDepth = (baseline*f_pixel)/disparity             #Depth in [cm]\n",
    "\n",
    "    return zDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
