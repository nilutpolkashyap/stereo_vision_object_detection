{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import depthai as dai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(queue):\n",
    "    # Get frame from queue\n",
    "    frame = queue.get()\n",
    "    # Convert frame to OpenCV format and return\n",
    "    return frame.getCvFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonoCamera(pipeline, isLeft):\n",
    "    # Configure mono camera\n",
    "    mono = pipeline.createMonoCamera()\n",
    "\n",
    "    # Set Camera Resolution\n",
    "    mono.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "    \n",
    "    if isLeft:\n",
    "        # Get left camera\n",
    "        mono.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "    else :\n",
    "        # Get right camera\n",
    "        mono.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    return mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No available devices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a445287acff7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Pipeline is defined, now we can connect to the device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mdai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Get output queues.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No available devices"
     ]
    }
   ],
   "source": [
    "output_left = \"images/stereoLeft/\"\n",
    "output_right = \"images/stereoRight/\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pipeline = dai.Pipeline()\n",
    "    \n",
    "    # Set up left and right cameras\n",
    "    monoLeft = getMonoCamera(pipeline, isLeft = True)\n",
    "    monoRight = getMonoCamera(pipeline, isLeft = False)\n",
    "    \n",
    "    # Set output Xlink for left camera\n",
    "    xoutLeft = pipeline.createXLinkOut()\n",
    "    xoutLeft.setStreamName(\"left\")\n",
    "    \n",
    "    # Set output Xlink for right camera\n",
    "    xoutRight = pipeline.createXLinkOut()\n",
    "    xoutRight.setStreamName(\"right\")\n",
    "    \n",
    "    # Attach cameras to output Xlink\n",
    "    monoLeft.out.link(xoutLeft.input)\n",
    "    monoRight.out.link(xoutRight.input)\n",
    "    \n",
    "    # Pipeline is defined, now we can connect to the device\n",
    "    with dai.Device(pipeline) as device:\n",
    "        \n",
    "        # Get output queues. \n",
    "        leftQueue = device.getOutputQueue(name=\"left\", maxSize=1)\n",
    "        rightQueue = device.getOutputQueue(name=\"right\", maxSize=1)\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        while(True):\n",
    "#             timer = T - int(time.time() - start)\n",
    "            \n",
    "            # Get left frame\n",
    "            leftFrame = getFrame(leftQueue)\n",
    "            # Get right frame\n",
    "            rightFrame = getFrame(rightQueue)\n",
    "            \n",
    "            cv2.imshow(\"Left Frame\", leftFrame)\n",
    "            cv2.imshow(\"Right Frame\", rightFrame)\n",
    "            \n",
    "#             grayR= cv2.cvtColor(leftFrame,cv2.COLOR_BGR2GRAY)\n",
    "#             grayL= cv2.cvtColor(rightFrame,cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Find the chess board corners\n",
    "            retR, cornersR = cv2.findChessboardCorners(rightFrame,(7,3),None)\n",
    "            retL, cornersL = cv2.findChessboardCorners(leftFrame,(7,3),None)\n",
    "            \n",
    "            print(retL, retR)\n",
    "            \n",
    "            if (retR == True) and (retL == True):\n",
    "                count+=1\n",
    "                cv2.imwrite(output_left+'imageR%d.png'%count, rightFrame)\n",
    "                cv2.imwrite(output_right+'imageL%d.png'%count, leftFrame)\n",
    "                print(\"Image saved\")\n",
    "            \n",
    "#             if timer <=0:\n",
    "#                 start = time.time()\n",
    "                \n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "                \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# print(\"Checking the right and left camera IDs:\")\n",
    "# print(\"Press (y) if IDs are correct and (n) to swap the IDs\")\n",
    "# print(\"Press enter to start the process >> \")\n",
    "# input()\n",
    "\n",
    "# Check for left and right camera IDs\n",
    "CamL_id = 1\n",
    "CamR_id = 2\n",
    "\n",
    "# CamL= cv2.VideoCapture(CamL_id)\n",
    "# CamR= cv2.VideoCapture(CamR_id)\n",
    "\n",
    "# for i in range(100):\n",
    "#     retL, frameL= CamL.read()\n",
    "#     retR, frameR= CamR.read()\n",
    "\n",
    "# cv2.imshow('imgL',frameL)\n",
    "# cv2.imshow('imgR',frameR)\n",
    "\n",
    "# if cv2.waitKey(0) & 0xFF == ord('y') or cv2.waitKey(0) & 0xFF == ord('Y'):\n",
    "#     CamL_id = 1\n",
    "#     CamR_id = 2\n",
    "#     print(\"Camera IDs maintained\")\n",
    "\n",
    "# elif cv2.waitKey(0) & 0xFF == ord('n') or cv2.waitKey(0) & 0xFF == ord('N'):\n",
    "#     CamL_id = 2\n",
    "#     CamR_id = 1\n",
    "#     print(\"Camera IDs swapped\")\n",
    "# else:\n",
    "#     print(\"Wrong input response\")\n",
    "#     exit(-1)\n",
    "CamR.release()\n",
    "CamL.release()\n",
    "\n",
    "CamL= cv2.VideoCapture(CamL_id)\n",
    "CamR= cv2.VideoCapture(CamR_id)\n",
    "output_path = \"./data/\"\n",
    "\n",
    "start = time.time()\n",
    "T = 10\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    timer = T - int(time.time() - start)\n",
    "    retR, frameR= CamR.read()\n",
    "    retL, frameL= CamL.read()\n",
    "    \n",
    "    img1_temp = frameL.copy()\n",
    "    cv2.putText(img1_temp,\"%r\"%timer,(50,50),1,5,(55,0,0),5)\n",
    "    cv2.imshow('imgR',frameR)\n",
    "    cv2.imshow('imgL',img1_temp)\n",
    "\n",
    "    grayR= cv2.cvtColor(frameR,cv2.COLOR_BGR2GRAY)\n",
    "    grayL= cv2.cvtColor(frameL,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retR, cornersR = cv2.findChessboardCorners(grayR,(9,6),None)\n",
    "    retL, cornersL = cv2.findChessboardCorners(grayL,(9,6),None)\n",
    "\n",
    "    # If corners are detected in left and right image then we save it.\n",
    "    if (retR == True) and (retL == True) and timer <=0:\n",
    "        count+=1\n",
    "        cv2.imwrite(output_path+'stereoR/img%d.png'%count,frameR)\n",
    "        cv2.imwrite(output_path+'stereoL/img%d.png'%count,frameL)\n",
    "    \n",
    "    if timer <=0:\n",
    "        start = time.time()\n",
    "    \n",
    "    # Press esc to exit\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        print(\"Closing the cameras!\")\n",
    "        break\n",
    "\n",
    "# Release the Cameras\n",
    "CamR.release()\n",
    "CamL.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# Set the path to the images captured by the left and right cameras\n",
    "pathL = \"images/stereoLeft/\"\n",
    "pathR = \"images/stereoRight/\"\n",
    "\n",
    "print(\"Extracting image coordinates of respective 3D pattern ....\\n\")\n",
    "\n",
    "# Termination criteria for refining the detected corners\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "objp = np.zeros((7*3,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:3].T.reshape(-1,2)\n",
    "\n",
    "img_ptsL = []\n",
    "img_ptsR = []\n",
    "obj_pts = []\n",
    "\n",
    "imagesLeft = sorted(glob.glob('images/stereoLeft/*.png'))\n",
    "imagesRight = sorted(glob.glob('images/stereoRight/*.png'))\n",
    "\n",
    "imagesLeft = imagesLeft[0:50]\n",
    "imagesRight = imagesRight[0:50]\n",
    "\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "\timgL = cv2.imread(imgLeft)\n",
    "\timgR = cv2.imread(imgRight)\n",
    "\timgL_gray = cv2.imread(imgLeft,0)\n",
    "\timgR_gray = cv2.imread(imgRight,0)\n",
    "\n",
    "\toutputL = imgL.copy()\n",
    "\toutputR = imgR.copy()\n",
    "\n",
    "\tretR, cornersR =  cv2.findChessboardCorners(outputR,(7,3),None)\n",
    "\tretL, cornersL = cv2.findChessboardCorners(outputL,(7,3),None)\n",
    "\n",
    "\tif retR and retL:\n",
    "\t\tobj_pts.append(objp)\n",
    "\t\tcv2.cornerSubPix(imgR_gray,cornersR,(11,11),(-1,-1),criteria)\n",
    "\t\tcv2.cornerSubPix(imgL_gray,cornersL,(11,11),(-1,-1),criteria)\n",
    "\t\tcv2.drawChessboardCorners(outputR,(7,3),cornersR,retR)\n",
    "\t\tcv2.drawChessboardCorners(outputL,(7,3),cornersL,retL)\n",
    "# \t\tcv2.imshow('cornersR',outputR)\n",
    "# \t\tcv2.imshow('cornersL',outputL)\n",
    "# \t\tcv2.waitKey(1)\n",
    "\n",
    "\t\timg_ptsL.append(cornersL)\n",
    "\t\timg_ptsR.append(cornersR)\n",
    "\n",
    "\n",
    "# print(\"Calculating left camera parameters ... \")\n",
    "# # Calibrating left camera\n",
    "# retL, mtxL, distL, rvecsL, tvecsL = cv2.calibrateCamera(obj_pts,img_ptsL,imgL_gray.shape[::-1],None,None)\n",
    "# hL,wL= imgL_gray.shape[:2]\n",
    "# new_mtxL, roiL= cv2.getOptimalNewCameraMatrix(mtxL,distL,(wL,hL),1,(wL,hL))\n",
    "\n",
    "# print(\"Calculating right camera parameters ... \")\n",
    "# # Calibrating right camera\n",
    "# retR, mtxR, distR, rvecsR, tvecsR = cv2.calibrateCamera(obj_pts,img_ptsR,imgR_gray.shape[::-1],None,None)\n",
    "# hR,wR= imgR_gray.shape[:2]\n",
    "# new_mtxR, roiR= cv2.getOptimalNewCameraMatrix(mtxR,distR,(wR,hR),1,(wR,hR))\n",
    "\n",
    "\n",
    "# print(\"Stereo calibration .....\")\n",
    "# flags = 0\n",
    "# flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "# # Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# # Hence intrinsic parameters are the same \n",
    "\n",
    "# criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# # This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "# retS, new_mtxL, distL, new_mtxR, distR, Rot, Trns, Emat, Fmat = cv2.stereoCalibrate(obj_pts,\n",
    "#                                                           img_ptsL,\n",
    "#                                                           img_ptsR,\n",
    "#                                                           new_mtxL,\n",
    "#                                                           distL,\n",
    "#                                                           new_mtxR,\n",
    "#                                                           distR,\n",
    "#                                                           imgL_gray.shape[::-1],\n",
    "#                                                           criteria_stereo,\n",
    "#                                                           flags)\n",
    "\n",
    "# # Once we know the transformation between the two cameras we can perform stereo rectification\n",
    "# # StereoRectify function\n",
    "# rectify_scale= 1 # if 0 image croped, if 1 image not croped\n",
    "# rect_l, rect_r, proj_mat_l, proj_mat_r, Q, roiL, roiR= cv2.stereoRectify(new_mtxL, distL, new_mtxR, distR,\n",
    "#                                                  imgL_gray.shape[::-1], Rot, Trns,\n",
    "#                                                  rectify_scale,(0,0))\n",
    "\n",
    "# # Use the rotation matrixes for stereo rectification and camera intrinsics for undistorting the image\n",
    "# # Compute the rectification map (mapping between the original image pixels and \n",
    "# # their transformed values after applying rectification and undistortion) for left and right camera frames\n",
    "# Left_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxL, distL, rect_l, proj_mat_l,\n",
    "#                                              imgL_gray.shape[::-1], cv2.CV_16SC2)\n",
    "# Right_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxR, distR, rect_r, proj_mat_r,\n",
    "#                                               imgR_gray.shape[::-1], cv2.CV_16SC2)\n",
    "\n",
    "\n",
    "# print(\"Saving paraeters ......\")\n",
    "# cv_file = cv2.FileStorage(\"images/params_py.xml\", cv2.FILE_STORAGE_WRITE)\n",
    "# cv_file.write(\"Left_Stereo_Map_x\",Left_Stereo_Map[0])\n",
    "# cv_file.write(\"Left_Stereo_Map_y\",Left_Stereo_Map[1])\n",
    "# cv_file.write(\"Right_Stereo_Map_x\",Right_Stereo_Map[0])\n",
    "# cv_file.write(\"Right_Stereo_Map_y\",Right_Stereo_Map[1])\n",
    "# cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesLeft = sorted(glob.glob('images/stereoLeft/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagesLeft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesLeft = imagesLeft[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagesLeft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
